module ParticleEngine

using Dates, JSON3, LinearAlgebra
using LibPQ
using Main.DatabaseFunctions: get_connection, get_latest_date

export get_velocity_grid, generate_particle_seeds, parse_depth_string

# –ö—ç—à –¥–ª—è —Å–µ—Ç–æ–∫ (date, depth, forecast_idx) -> —Å–µ—Ç–∫–∞
const VELOCITY_CACHE = Dict{Tuple{Date,Float64,Int},Any}()

"""
    get_velocity_grid(date::Date, depth_val::Float64, forecast_idx::Int)

–ó–∞–≥—Ä—É–∂–∞–µ—Ç –í–°–Æ —Å–µ—Ç–∫—É NEMO –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–π –¥–∞—Ç—ã, –≥–ª—É–±–∏–Ω—ã –∏ –≤—Ä–µ–º–µ–Ω–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ.
"""
function get_velocity_grid(date::Date, depth_val::Float64, forecast_idx::Int)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
    cache_key = (date, depth_val, forecast_idx)
    if haskey(VELOCITY_CACHE, cache_key)
        println("‚ôªÔ∏è  –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å–µ—Ç–∫—É")
        return VELOCITY_CACHE[cache_key]
    end
    
    conn = get_connection()
    
    try
        # –ò–º—è —Å–µ–∫—Ü–∏–∏
        partition_schema = Dates.format(date, "yyyy-mm-dd")
        table_name = "_nemo_$(partition_schema)"
        
        println("üîç –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ–π —Å–µ—Ç–∫–∏: $partition_schema, –≥–ª—É–±–∏–Ω–∞=$depth_val, –≤—Ä–µ–º—è=$forecast_idx")
        
        # –ü–†–û–°–¢–ï–ô–®–ò–ô –ó–ê–ü–†–û–° - –í–°–ï —Ç–æ—á–∫–∏ —Å–µ–∫—Ü–∏–∏
        query = """
        SELECT 
            ST_X(geom) as lon,
            ST_Y(geom) as lat,
            par
        FROM "$(partition_schema)"."$(table_name)"
        WHERE dat = \$1
        """
        
        result = LibPQ.execute(conn, query, [date])
        
        if isempty(result)
            @warn "‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ —Å–µ–∫—Ü–∏–∏" date
            return nothing
        end
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤ –ø–∞–º—è—Ç–∏
        lons = Float64[]
        lats = Float64[]
        u_vals = Float64[]
        v_vals = Float64[]
        
        processed = 0
        skipped_depth = 0
        skipped_time = 0
        
        for row in result
            parsed_data = JSON3.read(row.par)
            
            if length(parsed_data) > 0
                first_horizon = parsed_data[1]  # –ü–µ—Ä–≤—ã–π –≥–æ—Ä–∏–∑–æ–Ω—Ç –≥–ª—É–±–∏–Ω
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω—É–∂–Ω—ã—Ö –ø–æ–ª–µ–π
                if haskey(first_horizon, "depth") &&
                   haskey(first_horizon, "u") && 
                   haskey(first_horizon, "v")
                    
                    depth = first_horizon["depth"]
                    
                    # –§–∏–ª—å—Ç—Ä –≥–ª—É–±–∏–Ω—ã ¬±5 –º–µ—Ç—Ä–æ–≤
                    if abs(depth - depth_val) <= 5.0
                        u_array = first_horizon["u"]
                        v_array = first_horizon["v"]
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω–¥–µ–∫—Å –≤—Ä–µ–º–µ–Ω–∏
                        if forecast_idx <= length(u_array)
                            push!(lons, row.lon)
                            push!(lats, row.lat)
                            push!(u_vals, u_array[forecast_idx])
                            push!(v_vals, v_array[forecast_idx])
                            processed += 1
                        else
                            skipped_time += 1
                        end
                    else
                        skipped_depth += 1
                    end
                end
            end
        end
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
        grid_data = (
            lons=lons,
            lats=lats, 
            u=u_vals,
            v=v_vals,
            count=length(lons),
            metadata=Dict(
                "date" => string(date),
                "depth_requested" => depth_val,
                "forecast_idx" => forecast_idx,
                "total_points" => length(result),
                "processed" => processed,
                "skipped_depth" => skipped_depth,
                "skipped_time" => skipped_time
            )
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
        VELOCITY_CACHE[cache_key] = grid_data
        
        println("‚úÖ –°–µ—Ç–∫–∞: $(length(result)) —Å—Ç—Ä–æ–∫ ‚Üí $processed —Ç–æ—á–µ–∫ " *
                "(–ø—Ä–æ–ø—É—â–µ–Ω–æ: –≥–ª—É–±–∏–Ω–∞=$skipped_depth, –≤—Ä–µ–º—è=$skipped_time)")
        
        return grid_data
        
    catch e
        println("‚ùå –û—à–∏–±–∫–∞ –≤ get_velocity_grid: ", e)
        return nothing
    finally
        close(conn)
    end
end

"""
    generate_particle_seeds(count::Int)

–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–µ —Ç–æ—á–∫–∏ –ø–æ –í–°–ï–ô —Å–µ—Ç–∫–µ NEMO (–≤–µ—Å—å –æ–∫–µ–∞–Ω).
"""
function generate_particle_seeds(count::Int, depth_val::Float64)
    conn = get_connection()
    
    try
        # 1. –ü–æ–ª—É—á–∞–µ–º –¥–∞—Ç—É
        date_result = LibPQ.execute(conn, "SELECT MAX(dat) as latest_date FROM _nemo")
        latest_date = first(date_result).latest_date
        
        partition_schema = Dates.format(latest_date, "yyyy-mm-dd")
        table_name = "_nemo_$(partition_schema)"
        
        # 2. –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ô –ó–ê–ü–†–û–° - TABLESAMPLE
        query = """
WITH ocean_bbox AS (
    -- Bounding box –≤—Å–µ–≥–æ –æ–∫–µ–∞–Ω–∞ –¥–ª—è —ç—Ç–æ–π –¥–∞—Ç—ã/–≥–ª—É–±–∏–Ω—ã
    SELECT ST_Extent(geom) as bbox
    FROM "$(partition_schema)"."$(table_name)"
    WHERE dat = \$1 
      AND (par->0->>'depth')::float = \$2
),
random_points AS (
    -- –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ —Ç–æ—á–∫–∏ –≤ bounding box
    SELECT 
        ST_X(ST_GeneratePoints(bbox, \$3 * 2)) as lon,  -- √ó2 –¥–ª—è –∑–∞–ø–∞—Å–∞
        ST_Y(ST_GeneratePoints(bbox, \$3 * 2)) as lat
    FROM ocean_bbox
)
-- –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ –ø–æ–ø–∞–¥–∞—é—Ç –≤ —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–æ—á–∫–∏ —Å–µ—Ç–∫–∏
SELECT DISTINCT ON (rp.lon, rp.lat)
    rp.lon, rp.lat
FROM random_points rp
JOIN "$(partition_schema)"."$(table_name)" t 
  ON ST_DWithin(t.geom, ST_SetSRID(ST_MakePoint(rp.lon, rp.lat), 4326), 0.1)
WHERE t.dat = \$1 
  AND (t.par->0->>'depth')::float = \$2
LIMIT \$3;
        """
        
        println("üîç –ë—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —á–∞—Å—Ç–∏—Ü: TABLESAMPLE SYSTEM (0.5%)")
        
        result = LibPQ.execute(conn, query, [latest_date, depth_val, count])
        
        particles = [(lon=row.lon, lat=row.lat) for row in result]
        
        # 3. –ï—Å–ª–∏ –º–∞–ª–æ —Ç–æ—á–µ–∫ ‚Äî –¥–µ–ª–∞–µ–º –ø–æ–ª–Ω—ã–π –∑–∞–ø—Ä–æ—Å (—Ä–µ–¥–∫–∏–π —Å–ª—É—á–∞–π)
        if length(particles) < count * 0.8  # –ú–µ–Ω—å—à–µ 80%
            println("‚ö†Ô∏è  TABLESAMPLE –¥–∞–ª –º–∞–ª–æ —Ç–æ—á–µ–∫, –¥–µ–ª–∞–µ–º –ø–æ–ª–Ω—ã–π –∑–∞–ø—Ä–æ—Å")
            query_full = """
            SELECT 
                ST_X(geom) as lon,
                ST_Y(geom) as lat
            FROM "$(partition_schema)"."$(table_name)"
            WHERE dat = \$1
              AND (par->0->>'depth')::float = \$2
            ORDER BY RANDOM()
            LIMIT \$3
            """
            result = LibPQ.execute(conn, query_full, [latest_date, depth_val, count])
            particles = [(lon=row.lon, lat=row.lat) for row in result]
        end
        
        println("‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ $(length(particles)) —á–∞—Å—Ç–∏—Ü –∑–∞ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã")
        
        return particles
        
    catch e
        println("‚ùå –û—à–∏–±–∫–∞ –≤ generate_particle_seeds: ", e)
        # Fallback: —Å–ª—É—á–∞–π–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ –æ–∫–µ–∞–Ω–µ
        println("üîÑ Fallback: —Å–ª—É—á–∞–π–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –æ–∫–µ–∞–Ω–∞")
        return [(lon=-180 + 360*rand(), lat=-90 + 180*rand()) for _ in 1:count]
    finally
        close(conn)
    end
end

"""
    parse_depth_string(depth_str::String)

–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç "0p5" -> 0.5, "97" -> 97.0
"""
function parse_depth_string(depth_str::String)
    depth_map = Dict(
        "0p5" => 0.51,
        "97" => 97.04, 
        "1046" => 1045.85
    )
    return get(depth_map, depth_str, 0.51)
end

"""
    clear_cache()

–û—á–∏—â–∞–µ—Ç –∫—ç—à —Å–µ—Ç–æ–∫ (–ø–æ–ª–µ–∑–Ω–æ –ø—Ä–∏ —Å–º–µ–Ω–µ –¥–∞—Ç—ã).
"""
function clear_cache()
    empty!(VELOCITY_CACHE)
    println("üßπ –ö—ç—à —Å–µ—Ç–æ–∫ –æ—á–∏—â–µ–Ω")
end

end # module ParticleEngine
